"""
Inf√©rence Mask R-CNN - Pr√©diction sur nouvelles images
Segmentation des toitures cadastrales

Fonctionnalit√©s:
- Temps d'inf√©rence par image
- R√©sum√© global pour les dossiers
- Export des masques individuels
- Rapports JSON d√©taill√©s
"""

import os
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from torchvision.transforms import v2 as T
from torchvision.models.detection import maskrcnn_resnet50_fpn_v2
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from dotenv import load_dotenv
from pathlib import Path
from datetime import datetime
import time
import json
import yaml

# Charger les variables d'environnement
load_dotenv()
# =============================================================================
# CONFIGURATION
# =============================================================================

def load_classes(yaml_path=None):
    path = yaml_path or os.getenv("CLASSES_FILE", "classes.yaml")
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)['classes']
    
    # Palette de couleurs auto-g√©n√©r√©e pour toutes les classes
_PALETTE = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 165, 0),
    (128, 0, 128), (0, 255, 255), (255, 20, 147), (0, 128, 0),
]
CLASSES = load_classes()

COLORS = {
    cls: _PALETTE[i % len(_PALETTE)]
    for i, cls in enumerate(CLASSES[1:])  # on ignore __background__
}




CONFIG = {
    "model_path": os.getenv("SEGMENTATION_MODEL_PATH", "./output/best_model.pth"),
    "input_dir": os.getenv("SEGMENTATION_TEST_IMAGES_DIR", "./test_images"),
    "classes_file": os.getenv("CLASSES_FILE", "classes.yaml"),
    "output_dir": os.getenv("SEGMENTATION_OUTPUT_DIR", "./predictions"),
    "score_threshold": 0.5,
    "export_masks": False,
    "show_display": False,
}

# =============================================================================
# UTILITAIRES
# =============================================================================

def format_time(seconds):
    """Formater les secondes en format lisible"""
    if seconds < 1:
        return f"{seconds*1000:.1f} ms"
    elif seconds < 60:
        return f"{seconds:.2f} s"
    else:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}m {secs:.1f}s"


# =============================================================================
# MOD√àLE
# =============================================================================

def get_model(num_classes):
    model = maskrcnn_resnet50_fpn_v2(weights=None)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)
    return model


def load_model(checkpoint_path, device):
    model = get_model(len(CLASSES))
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    print(f"‚úÖ Mod√®le charg√©: {checkpoint_path}")
    return model


# =============================================================================
# INF√âRENCE
# =============================================================================

def predict(model, image_path, device, score_threshold=0.5):
    image = Image.open(image_path).convert("RGB")
    image_tensor = T.ToTensor()(image)
    
    start_time = time.time()
    with torch.no_grad():
        predictions = model([image_tensor.to(device)])
    inference_time = time.time() - start_time
    
    pred = predictions[0]
    keep = pred['scores'] > score_threshold
    
    result = {
        'boxes': pred['boxes'][keep].cpu().numpy(),
        'labels': pred['labels'][keep].cpu().numpy(),
        'scores': pred['scores'][keep].cpu().numpy(),
        'masks': pred['masks'][keep].cpu().numpy(),
        'inference_time': inference_time,
    }
    return image, result


def calculate_surface(mask):
    return int(np.sum(mask > 0.5))


# =============================================================================
# VISUALISATION
# =============================================================================

def visualize_predictions(image, predictions, output_path=None, show=True):
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    
    axes[0].imshow(image)
    axes[0].set_title("Image originale")
    axes[0].axis('off')
    
    axes[1].imshow(image)
    
    masks = predictions['masks']
    boxes = predictions['boxes']
    labels = predictions['labels']
    scores = predictions['scores']
    inference_time = predictions.get('inference_time', 0)
    
    overlay = np.zeros((*np.array(image).shape[:2], 4))
    
    for i, (mask, box, label, score) in enumerate(zip(masks, boxes, labels, scores)):
        class_name = CLASSES[label]
        color = COLORS.get(class_name, (128, 128, 128))
        color_normalized = [c/255 for c in color]
        
        mask_binary = mask[0] > 0.5
        overlay[mask_binary] = [*color_normalized, 0.5]
        
        x1, y1, x2, y2 = box
        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                                  edgecolor=color_normalized, facecolor='none')
        axes[1].add_patch(rect)
        
        surface = calculate_surface(mask[0])
        label_text = f"{class_name}\n{score:.2f} | {surface:,} px"
        axes[1].text(x1, y1-10, label_text, fontsize=8, color='white',
                     bbox=dict(boxstyle='round', facecolor=color_normalized, alpha=0.8))
    
    axes[1].imshow(overlay)
    axes[1].set_title(f"Pr√©dictions ({len(masks)} objets) | ‚è±Ô∏è {format_time(inference_time)}")
    axes[1].axis('off')
    
    plt.tight_layout()
    if output_path:
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
    if show:
        plt.show()
    plt.close()


def export_masks(predictions, output_dir, image_name):
    os.makedirs(output_dir, exist_ok=True)
    for i, (mask, label, score) in enumerate(zip(predictions['masks'], predictions['labels'], predictions['scores'])):
        class_name = CLASSES[label]
        mask_binary = (mask[0] > 0.5).astype(np.uint8) * 255
        mask_path = os.path.join(output_dir, f"{image_name}_{i:02d}_{class_name}_{score:.2f}.png")
        Image.fromarray(mask_binary).save(mask_path)


def generate_report(predictions, image_name):
    report = {
        'image': image_name,
        'timestamp': datetime.now().isoformat(),
        'inference_time_ms': predictions.get('inference_time', 0) * 1000,
        'total_objects': len(predictions['labels']),
        'surfaces_by_class': {},
        'details': []
    }
    
    for class_name in CLASSES[1:]:
        report['surfaces_by_class'][class_name] = {'count': 0, 'total_surface_px': 0}
    
    for i, (mask, label, score, box) in enumerate(zip(
        predictions['masks'], predictions['labels'], predictions['scores'], predictions['boxes']
    )):
        class_name = CLASSES[label]
        surface = calculate_surface(mask[0])
        report['surfaces_by_class'][class_name]['count'] += 1
        report['surfaces_by_class'][class_name]['total_surface_px'] += surface
        report['details'].append({
            'id': i, 'class': class_name, 'score': float(score),
            'surface_px': int(surface), 'bbox': box.tolist()
        })
    return report


# =============================================================================
# R√âSUM√â GLOBAL
# =============================================================================

def generate_summary(all_reports, output_dir, total_processing_time):
    summary = {
        'timestamp': datetime.now().isoformat(),
        'model': 'Mask R-CNN',
        'total_images': len(all_reports),
        'total_processing_time_s': total_processing_time,
        'avg_inference_time_ms': 0,
        'total_objects': 0,
        'objects_by_class': {c: 0 for c in CLASSES[1:]},
        'surfaces_by_class': {c: 0 for c in CLASSES[1:]},
        'per_image_stats': []
    }
    
    total_inference_time = 0
    for report in all_reports:
        total_inference_time += report['inference_time_ms']
        summary['total_objects'] += report['total_objects']
        for class_name, data in report['surfaces_by_class'].items():
            summary['objects_by_class'][class_name] += data['count']
            summary['surfaces_by_class'][class_name] += data['total_surface_px']
        summary['per_image_stats'].append({
            'image': report['image'],
            'objects': report['total_objects'],
            'inference_time_ms': report['inference_time_ms']
        })
    
    summary['avg_inference_time_ms'] = total_inference_time / len(all_reports) if all_reports else 0
    
    # Sauvegarder JSON
    with open(os.path.join(output_dir, "summary.json"), 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # Sauvegarder TXT
    total_surface = sum(summary['surfaces_by_class'].values())
    with open(os.path.join(output_dir, "summary.txt"), 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("   R√âSUM√â D'INF√âRENCE - MASK R-CNN CADASTRAL\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"üìÖ Date: {summary['timestamp']}\n")
        f.write(f"üñºÔ∏è  Images trait√©es: {summary['total_images']}\n")
        f.write(f"‚è±Ô∏è  Temps total: {format_time(summary['total_processing_time_s'])}\n")
        f.write(f"‚è±Ô∏è  Temps moyen/image: {summary['avg_inference_time_ms']:.1f} ms\n")
        f.write(f"üéØ Total objets: {summary['total_objects']}\n\n")
        f.write("-" * 70 + "\n")
        f.write(f"{'Classe':<25} {'Objets':>10} {'Surface (px)':>15} {'%':>10}\n")
        f.write("-" * 70 + "\n")
        for class_name in CLASSES[1:]:
            count = summary['objects_by_class'][class_name]
            surface = summary['surfaces_by_class'][class_name]
            pct = (surface / total_surface * 100) if total_surface > 0 else 0
            f.write(f"{class_name:<25} {count:>10} {surface:>15,} {pct:>9.1f}%\n")
        f.write("-" * 70 + "\n")
        f.write(f"{'TOTAL':<25} {summary['total_objects']:>10} {total_surface:>15,} {'100.0%':>10}\n")
        f.write("\n" + "-" * 70 + "\n")
        f.write("D√âTAILS PAR IMAGE\n")
        f.write("-" * 70 + "\n")
        f.write(f"{'Image':<40} {'Objets':>10} {'Temps (ms)':>15}\n")
        f.write("-" * 70 + "\n")
        for stat in summary['per_image_stats']:
            img_name = stat['image'][:38] + '..' if len(stat['image']) > 40 else stat['image']
            f.write(f"{img_name:<40} {stat['objects']:>10} {stat['inference_time_ms']:>15.1f}\n")
        f.write("=" * 70 + "\n")
    
    return summary


def print_summary(summary):
    print("\n" + "=" * 70)
    print("   üìä R√âSUM√â GLOBAL - MASK R-CNN")
    print("=" * 70)
    print(f"\n   üñºÔ∏è  Images trait√©es:     {summary['total_images']}")
    print(f"   ‚è±Ô∏è  Temps total:          {format_time(summary['total_processing_time_s'])}")
    print(f"   ‚è±Ô∏è  Temps moyen/image:    {summary['avg_inference_time_ms']:.1f} ms")
    print(f"   üéØ Total objets:         {summary['total_objects']}")
    
    total_surface = sum(summary['surfaces_by_class'].values())
    print(f"\n   üìã Par classe:")
    print(f"   {'-'*50}")
    for class_name in CLASSES[1:]:
        count = summary['objects_by_class'][class_name]
        surface = summary['surfaces_by_class'][class_name]
        pct = (surface / total_surface * 100) if total_surface > 0 else 0
        if count > 0:
            print(f"      ‚Ä¢ {class_name}: {count} objets | {surface:,} px ({pct:.1f}%)")
    print("\n" + "=" * 70)


# =============================================================================
# BATCH PROCESSING
# =============================================================================

def process_directory(model, input_dir, output_dir, device, score_threshold=0.5, export_masks_flag=False, show_display=False):
    os.makedirs(output_dir, exist_ok=True)
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp'}
    image_paths = sorted([p for p in Path(input_dir).iterdir() if p.suffix.lower() in image_extensions])
    
    if not image_paths:
        print(f"‚ùå Aucune image trouv√©e dans {input_dir}")
        return []
    
    print(f"\nüñºÔ∏è  {len(image_paths)} images √† traiter\n")
    
    all_reports = []
    start_total = time.time()
    
    for idx, img_path in enumerate(image_paths, 1):
        print(f"[{idx}/{len(image_paths)}] üîç {img_path.name}")
        
        image, predictions = predict(model, str(img_path), device, score_threshold)
        
        output_path = os.path.join(output_dir, f"{img_path.stem}_pred.png")
        visualize_predictions(image, predictions, output_path, show=show_display)
        
        if export_masks_flag and len(predictions['masks']) > 0:
            export_masks(predictions, os.path.join(output_dir, "masks", img_path.stem), img_path.stem)
        
        report = generate_report(predictions, img_path.name)
        all_reports.append(report)
        print(f"   ‚úÖ {report['total_objects']} objets | ‚è±Ô∏è {report['inference_time_ms']:.1f} ms")
    
    total_processing_time = time.time() - start_total
    
    # Sauvegarder les rapports
    with open(os.path.join(output_dir, "reports.json"), 'w', encoding='utf-8') as f:
        json.dump(all_reports, f, indent=2, ensure_ascii=False)
    
    # G√©n√©rer le r√©sum√©
    summary = generate_summary(all_reports, output_dir, total_processing_time)
    print_summary(summary)
    
    print(f"\nüìÅ R√©sultats sauvegard√©s dans: {output_dir}")
    print(f"   ‚îú‚îÄ‚îÄ *_pred.png (visualisations)")
    print(f"   ‚îú‚îÄ‚îÄ reports.json (rapports d√©taill√©s)")
    print(f"   ‚îú‚îÄ‚îÄ summary.json (r√©sum√© JSON)")
    print(f"   ‚îî‚îÄ‚îÄ summary.txt (r√©sum√© lisible)")
    
    return all_reports


# =============================================================================
# MAIN
# =============================================================================

def main():
    # Configuration depuis variables d'environnement
    model_path = CONFIG["model_path"]
    input_dir = CONFIG["input_dir"]
    output_dir = CONFIG["output_dir"]
    score_threshold = CONFIG["score_threshold"]
    export_masks_flag = CONFIG["export_masks"]
    show_display = CONFIG["show_display"]
    
    # V√©rifications
    if not os.path.exists(model_path):
        print(f"‚ùå Mod√®le non trouv√©: {model_path}")
        print(f"   D√©finissez SEGMENTATION_MODEL_PATH")
        return
    
    if not os.path.exists(input_dir):
        print(f"‚ùå Dossier d'images non trouv√©: {input_dir}")
        print(f"   D√©finissez SEGMENTATION_TEST_IMAGES_DIR")
        return
    
    print("=" * 70)
    print("   üöÄ INF√âRENCE MASK R-CNN CADASTRAL")
    print("=" * 70)
    print(f"\nüìÇ Configuration:")
    print(f"   ‚Ä¢ Mod√®le:      {model_path}")
    print(f"   ‚Ä¢ Images:      {input_dir}")
    print(f"   ‚Ä¢ Sortie:      {output_dir}")
    print(f"   ‚Ä¢ Seuil:       {score_threshold}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   ‚Ä¢ Device:      {device}")
    
    model = load_model(model_path, device)
    
    input_path = Path(input_dir)
    
    if input_path.is_dir():
        process_directory(model, str(input_path), output_dir, device, score_threshold, export_masks_flag, show_display)
    else:
        os.makedirs(output_dir, exist_ok=True)
        print(f"\nüîç Traitement: {input_path.name}")
        
        image, predictions = predict(model, str(input_path), device, score_threshold)
        
        output_path = os.path.join(output_dir, f"{input_path.stem}_pred.png")
        visualize_predictions(image, predictions, output_path, show=show_display)
        
        if export_masks_flag and len(predictions['masks']) > 0:
            export_masks(predictions, os.path.join(output_dir, "masks"), input_path.stem)
        
        report = generate_report(predictions, input_path.name)
        print(f"\n{'='*60}")
        print(f"üìä RAPPORT - {report['image']}")
        print(f"{'='*60}")
        print(f"   ‚è±Ô∏è  Temps d'inf√©rence: {report['inference_time_ms']:.1f} ms")
        print(f"   üéØ Objets d√©tect√©s: {report['total_objects']}")
        for class_name, data in report['surfaces_by_class'].items():
            if data['count'] > 0:
                print(f"      ‚Ä¢ {class_name}: {data['count']} objets, {data['total_surface_px']:,} px")
        print(f"{'='*60}")
        
        with open(os.path.join(output_dir, f"{input_path.stem}_report.json"), 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)


if __name__ == "__main__":
    main()
